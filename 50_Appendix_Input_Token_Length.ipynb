{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A copy of the main model performance test but where we split the \"Answers\" text into paragraphs, using the newline character as a separator. This is done to check of changing the granularity of the embedding changes the model performance.  \n",
    "\n",
    "Spoiler alert - it does. Don't make the text that goes to your embedding model too small!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv('./inputdata/Mental_Health_FAQ.csv')\n",
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      98.000000\n",
      "mean      261.030612\n",
      "std       232.316060\n",
      "min        16.000000\n",
      "25%        84.750000\n",
      "50%       197.000000\n",
      "75%       396.000000\n",
      "max      1453.000000\n",
      "Name: word_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the words in each entry in the \"Answers\" column of the dataframe and output the minimum, maximum and average word count \n",
    "raw_data['word_count'] = raw_data['Answers'].apply(lambda x: len(str(x).split(\" \")))\n",
    "print(raw_data['word_count'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    600.000000\n",
      "mean      43.471667\n",
      "std       35.725571\n",
      "min        1.000000\n",
      "25%       16.000000\n",
      "50%       35.000000\n",
      "75%       60.000000\n",
      "max      215.000000\n",
      "Name: word_count, dtype: float64\n",
      "The number of rows that contain more than 128 words is 18 or 3.0% of the total\n"
     ]
    }
   ],
   "source": [
    "# create a new dataframe. Each row will consist of the Question_ID, the Questions column but the last column will be one paragraph of the Answers column. \n",
    "# This way if a value from the original Answers column consists of two paragraphs, the new dataframe will split that into two rows\n",
    "data = []\n",
    "for index, row in raw_data.iterrows():\n",
    "    answer = row['Answers']\n",
    "    if \"\\n\" in answer:\n",
    "        paragraphs = answer.split(\"\\n\")\n",
    "        for paragraph in paragraphs:\n",
    "            data.append({'Question_ID': row['Question_ID'], 'Questions': row['Questions'], 'Answers': paragraph})\n",
    "    else:\n",
    "        data.append({'Question_ID': row['Question_ID'], 'Questions': row['Questions'], 'Answers': answer})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['word_count'] = df['Answers'].apply(lambda x: len(str(x).split(\" \")))\n",
    "print(df['word_count'].describe())\n",
    "\n",
    "n = 128\n",
    "count = df['word_count'][df['word_count'] > n].count()\n",
    "print(\"The number of rows that contain more than \" + str(n) + \" words is \" + str(count) + \" or \" + str(count/len(df)*100) + \"% of the total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question_ID</th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1590140</td>\n",
       "      <td>What does it mean to have a mental illness?</td>\n",
       "      <td>Mental illnesses are health conditions that di...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1590140</td>\n",
       "      <td>What does it mean to have a mental illness?</td>\n",
       "      <td>Mental illnesses fall along a continuum of sev...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1590140</td>\n",
       "      <td>What does it mean to have a mental illness?</td>\n",
       "      <td>It is important to know that mental illnesses ...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1590140</td>\n",
       "      <td>What does it mean to have a mental illness?</td>\n",
       "      <td>Similarly to how one would treat diabetes with...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2110618</td>\n",
       "      <td>Who does mental illness affect?</td>\n",
       "      <td>It is estimated that mental illness affects 1 ...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Question_ID                                    Questions   \n",
       "0      1590140  What does it mean to have a mental illness?  \\\n",
       "1      1590140  What does it mean to have a mental illness?   \n",
       "2      1590140  What does it mean to have a mental illness?   \n",
       "3      1590140  What does it mean to have a mental illness?   \n",
       "4      2110618              Who does mental illness affect?   \n",
       "\n",
       "                                             Answers  word_count  \n",
       "0  Mental illnesses are health conditions that di...          32  \n",
       "1  Mental illnesses fall along a continuum of sev...          68  \n",
       "2  It is important to know that mental illnesses ...          43  \n",
       "3  Similarly to how one would treat diabetes with...          65  \n",
       "4  It is estimated that mental illness affects 1 ...          46  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model all-MiniLM-L6-v2\n",
      "Embedding on paragraphs\n"
     ]
    }
   ],
   "source": [
    "model_list = [\"all-MiniLM-L6-v2\", \"text-embedding-ada-002\", \"instructor_large\", \"instructor_xl\", \"e5-base-v2\", \"e5-large-v2\"]\n",
    "\n",
    "model_to_use = model_list[0]\n",
    "print(\"Using model \" + model_to_use)\n",
    "\n",
    "\n",
    "dbf_postscript = \"\"\n",
    "print(\"Embedding on paragraphs\")\n",
    "dbf_postscript = \"_paragraphs\"\n",
    "data_frame_to_use = df\n",
    "\n",
    "dbf = \".\\db_\" + model_to_use + dbf_postscript "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define a dictionary where the keys are the model names and the values are the functions or actions we want to take for each one.\n",
    "\n",
    "The challenge here is that the actions for each model_to_use value are not consistent - in some cases, you're importing a model \n",
    "and in others, you're setting a value.\n",
    "\n",
    "For the models where you're importing a model and instantiating it with a string, define a function that does that and use \n",
    "the function in your dictionary. For the models where you're just setting a string, you can just put the string in your dictionary.\n",
    "'''\n",
    "\n",
    "def import_instructor_model(model_name):\n",
    "    from InstructorEmbedding import INSTRUCTOR\n",
    "    return INSTRUCTOR(model_name)\n",
    "\n",
    "def import_sentence_transformer(model_name):\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    return SentenceTransformer(model_name)\n",
    "\n",
    "def import_openai_model(model_name):\n",
    "    import openai\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    return model_name\n",
    "\n",
    "model_to_function_map = {\n",
    "    \"instructor_large\": lambda: import_instructor_model('hkunlp/instructor-large'),\n",
    "    \"instructor_xl\": lambda: import_instructor_model('hkunlp/instructor-xl'),\n",
    "    \"e5-base-v2\": 'intfloat/e5-base-v2',\n",
    "    \"e5-large-v2\": 'intfloat/e5-large-v2',\n",
    "    \"all-MiniLM-L6-v2\": lambda: import_sentence_transformer('sentence-transformers/all-MiniLM-L6-v2'),\n",
    "    \"text-embedding-ada-002\": lambda: import_openai_model('text-embedding-ada-002'),\n",
    "}\n",
    "\n",
    "if model_to_use not in model_to_function_map:\n",
    "    raise ValueError(f\"model_to_use must be one of {', '.join(model_to_function_map.keys())}\")\n",
    "\n",
    "model = model_to_function_map[model_to_use]\n",
    "if callable(model):\n",
    "    model = model()  # Call the function if the model is a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: .\\db_all-MiniLM-L6-v2_paragraphs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "from create_vector_db import InstructorEmbeddingModel, e5EmbeddingModel, AllMiniLML6v2, OpenAIAda\n",
    "from importlib import reload\n",
    "import create_vector_db\n",
    "\n",
    "reload(create_vector_db)\n",
    "\n",
    "model_class_map = {\n",
    "    \"instructor_large\": InstructorEmbeddingModel,\n",
    "    \"instructor_xl\": InstructorEmbeddingModel,\n",
    "    \"e5-base-v2\": e5EmbeddingModel,\n",
    "    \"e5-large-v2\": e5EmbeddingModel,\n",
    "    \"all-MiniLM-L6-v2\": AllMiniLML6v2,\n",
    "    \"text-embedding-ada-002\": OpenAIAda\n",
    "}\n",
    "\n",
    "if model_to_use not in model_class_map:\n",
    "    raise ValueError(f\"model_to_use must be one of {', '.join(model_class_map.keys())}\")\n",
    "\n",
    "my_model = model_class_map[model_to_use](model, dbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While the EmbeddingModel class has a method to create embeddings based on other columns, or a combination of columns,\n",
    "# I have only tested this when we use the \"Answers\" column as the source of the embeddings.  \n",
    "\n",
    "name_answer = \"Answers\"\n",
    "#name_combined = \"Combined\"\n",
    "#name_faq = \"Questions\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No embedding_function provided, using default embedding function: SentenceTransformerEmbeddingFunction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database already exists, reading from it\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    client = my_model.client\n",
    "    collection_answers = client.get_collection(name=name_answer.lower())\n",
    "    #collection_question = client.get_collection(name=name_faq.lower())\n",
    "    #collection_combined = client.get_collection(name=name_combined.lower())\n",
    "    print(\"Database already exists, reading from it\")\n",
    "\n",
    "except (NameError, ValueError):\n",
    "    print(\"Collection does not exist, creating it\")\n",
    "    my_model.embed_and_save_knowledge_base(text_faq_data_df = data_frame_to_use, embedding_column = name_answer)\n",
    "    client = my_model.client\n",
    "    collection_answers = client.get_collection(name=name_answer.lower())\n",
    "    #collection_question = client.get_collection(name=name_faq.lower())\n",
    "    #collection_combined = client.get_collection(name=name_combined.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File question_embeddings\\all-MiniLM-L6-v2.csv already exists so just loading it\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "question_embedding_file_to_create = Path(\"./question_embeddings\") / f\"{model_to_use}.csv\"\n",
    "\n",
    "if question_embedding_file_to_create.is_file():\n",
    "    print(f\"File {question_embedding_file_to_create} already exists so just loading it\")\n",
    "    questions_df = pd.read_csv(question_embedding_file_to_create)\n",
    "    # Convert the value in row['Embeddings'] from a string to a list\n",
    "    questions_df['Embeddings'] = questions_df['Embeddings'].apply(ast.literal_eval)\n",
    "else:\n",
    "    questions_df = pd.DataFrame(raw_data['Questions'])\n",
    "    questions_df = my_model.embed_test_questions(questions_df, 'Questions')\n",
    "    questions_df.to_csv(question_embedding_file_to_create, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions: 98\n",
      "Top Matched questions: 60\n",
      "Matched questions: 76\n"
     ]
    }
   ],
   "source": [
    "def check_matches(row):\n",
    "    embedding = row['Embeddings']\n",
    "    search_results = my_model.search_collection_using_embedding(collection_answers, embedding=embedding, num_docs=4)\n",
    "    \n",
    "    # Check if current question is in search results\n",
    "    match = row['Questions'] in search_results['Questions'].values\n",
    "\n",
    "    # Check if current question is the top match in search results. The top match has the highest cosine similarity or lowest Score\n",
    "    # I could equally have rerun the search with num_docs=1 and checked if the expected answer was the only result\n",
    "    top_match = row['Questions'] == search_results.loc[search_results['Scores'].idxmin(), 'Questions']\n",
    "\n",
    "    return pd.Series([match, top_match])\n",
    "\n",
    "# Apply check_matches to each row in questions_df and count True values\n",
    "questions_df[['Match', 'Top_Match']] = questions_df.apply(check_matches, axis=1)\n",
    "match_count = questions_df['Match'].sum()\n",
    "top_match_count = questions_df['Top_Match'].sum()\n",
    "\n",
    "print(f\"Total questions: {len(questions_df)}\")\n",
    "print(f\"Top Matched questions: {top_match_count}\")\n",
    "print(f\"Matched questions: {match_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc81e089c2f5279f21356681884ce5bcbbb440b9afbfbfc737ea25b5a34dac96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
